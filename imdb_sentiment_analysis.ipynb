{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('wordnet')\r\n",
        "\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /home/azureuser/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1679887526389
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Dataset\r\n",
        "\r\n",
        "subscription_id = 'b47bd811-d493-4457-b1d3-55f3dd8c85ed'\r\n",
        "resource_group = 'DP_100_RG'\r\n",
        "workspace_name = 'sentiment-analysis-ws'\r\n",
        "\r\n",
        "workspace = Workspace(subscription_id, resource_group, workspace_name)\r\n",
        "\r\n",
        "train_df = Dataset.get_by_name(workspace, name='train')\r\n",
        "train_df = train_df.to_pandas_dataframe()\r\n",
        "\r\n",
        "test_df = Dataset.get_by_name(workspace, name='test')\r\n",
        "test_df = test_df.to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\nFailed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\nFailed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\nFailed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\nFailed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\nFailed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\nFailed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\nFailed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\nFailed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\nFailed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\nFailed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\nFailed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679887530067
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "                                                text  label\n0  I grew up (b. 1965) watching and loving the Th...      0\n1  When I put this movie in my DVD player, and sa...      0\n2  Why do people who do not know what a particula...      0\n3  Even though I have great interest in Biblical ...      0\n4  Im a die hard Dads Army fan and nothing will e...      1",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I grew up (b. 1965) watching and loving the Th...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>When I put this movie in my DVD player, and sa...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Why do people who do not know what a particula...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Even though I have great interest in Biblical ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Im a die hard Dads Army fan and nothing will e...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679887530274
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.iloc[0, 0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "'I grew up (b. 1965) watching and loving the Thunderbirds. All my mates at school watched. We played \"Thunderbirds\" before school, during lunch and after school. We all wanted to be Virgil or Scott. No one wanted to be Alan. Counting down from 5 became an art form. I took my children to see the movie hoping they would get a glimpse of what I loved as a child. How bitterly disappointing. The only high point was the snappy theme tune. Not that it could compare with the original score of the Thunderbirds. Thankfully early Saturday mornings one television channel still plays reruns of the series Gerry Anderson and his wife created. Jonatha Frakes should hand in his directors chair, his version was completely hopeless. A waste of film. Utter rubbish. A CGI remake may be acceptable but replacing marionettes with Homo sapiens subsp. sapiens was a huge error of judgment.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679887530474
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "(40000, 2)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679887530668
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df[:20000]\r\n",
        "train_df.label.value_counts()*100/len(train_df)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "0    50.12\n1    49.88\nName: label, dtype: float64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679887530881
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "(5000, 2)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679887531096
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.label.value_counts()*100/len(train_df)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "0    50.12\n1    49.88\nName: label, dtype: float64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679887531298
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.label.value_counts()*100/len(train_df)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "1    12.525\n0    12.475\nName: label, dtype: float64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679887531502
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Preprocessing - Tokenization, Lowering, Stop Word Removal, Removal of non-alphanumeric characters & Lemmatization"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\r\n",
        "lemmatizer = nltk.WordNetLemmatizer()\r\n",
        "\r\n",
        "def preprocess(line):\r\n",
        "    words = nltk.word_tokenize(line) # tokenization\r\n",
        "    words = [word.lower() for word in words] # lower casing\r\n",
        "    words = [word for word in words if word not in stopwords] # removal of stop words\r\n",
        "    words = [word for word in words if word.isalpha()] # removal of non-alphanumeric characters\r\n",
        "    words = [lemmatizer.lemmatize(word) for word in words] # lemmatizaion\r\n",
        "    return(words)\r\n",
        "\r\n",
        "train_df.text.apply(preprocess)\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "0        [grew, b, watching, loving, thunderbird, mate,...\n1        [put, movie, dvd, player, sat, coke, chip, exp...\n2        [people, know, particular, time, past, like, f...\n3        [even, though, great, interest, biblical, movi...\n4        [im, die, hard, dad, army, fan, nothing, ever,...\n                               ...                        \n19995    [required, watch, movie, work, pay, contrary, ...\n19996    [white, noise, potential, one, talked, movie, ...\n19997    [five, deadly, venom, great, action, movie, wr...\n19998    [ali, g, indahouse, got, one, funniest, film, ...\n19999    [found, six, seven, watching, one, altman, tou...\nName: text, Length: 20000, dtype: object"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679887575012
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline(data):\r\n",
        "    X_tfidf = tfidf_vec.transform(data['text'])\r\n",
        "    X_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vec.get_feature_names_out())\r\n",
        "    y_df = data['label']\r\n",
        "    return(X_df, y_df)\r\n"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679890154551
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vec = TfidfVectorizer(analyzer=preprocess).fit(train_df['text'])\r\n",
        "X_train, y_train = pipeline(train_df)\r\n",
        "X_test, y_test = pipeline(test_df)"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679890268605
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "\r\n",
        "rf = RandomForestClassifier()\r\n",
        "rf.fit(X_train, y_train)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "RandomForestClassifier()",
            "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679890732373
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rf.predict(X_test)"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679890797221
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "train_acc = accuracy_score(y_train, rf.predict(X_train))\r\n",
        "test_acc = accuracy_score(y_test, rf.predict(X_test))"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679890946920
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Accuracy: \", train_acc)\r\n",
        "print(\"Test Accuracy: \", test_acc)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training Accuracy:  1.0\nTest Accuracy:  0.8526\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679890959347
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['processed_data'] = train_df.text.apply(preprocess)\r\n",
        "test_df['processed_data'] = test_df.text.apply(preprocess)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679891147885
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv('./processed_train.csv', index=False)"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679891762497
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('processed_train.csv')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/plain": "                                                    text  label  \\\n0      I grew up (b. 1965) watching and loving the Th...      0   \n1      When I put this movie in my DVD player, and sa...      0   \n2      Why do people who do not know what a particula...      0   \n3      Even though I have great interest in Biblical ...      0   \n4      Im a die hard Dads Army fan and nothing will e...      1   \n...                                                  ...    ...   \n19995  I was required to watch the movie for my work,...      0   \n19996  \"White Noise\" had potential to be one of the m...      0   \n19997  The Five Deadly Venoms is a great kung-fu acti...      1   \n19998  Ali G Indahouse has got to be one of the funni...      1   \n19999  I found myself at sixes and sevens while watch...      1   \n\n                                          processed_data  \n0      ['grew', 'b', 'watching', 'loving', 'thunderbi...  \n1      ['put', 'movie', 'dvd', 'player', 'sat', 'coke...  \n2      ['people', 'know', 'particular', 'time', 'past...  \n3      ['even', 'though', 'great', 'interest', 'bibli...  \n4      ['im', 'die', 'hard', 'dad', 'army', 'fan', 'n...  \n...                                                  ...  \n19995  ['required', 'watch', 'movie', 'work', 'pay', ...  \n19996  ['white', 'noise', 'potential', 'one', 'talked...  \n19997  ['five', 'deadly', 'venom', 'great', 'action',...  \n19998  ['ali', 'g', 'indahouse', 'got', 'one', 'funni...  \n19999  ['found', 'six', 'seven', 'watching', 'one', '...  \n\n[20000 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>processed_data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I grew up (b. 1965) watching and loving the Th...</td>\n      <td>0</td>\n      <td>['grew', 'b', 'watching', 'loving', 'thunderbi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>When I put this movie in my DVD player, and sa...</td>\n      <td>0</td>\n      <td>['put', 'movie', 'dvd', 'player', 'sat', 'coke...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Why do people who do not know what a particula...</td>\n      <td>0</td>\n      <td>['people', 'know', 'particular', 'time', 'past...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Even though I have great interest in Biblical ...</td>\n      <td>0</td>\n      <td>['even', 'though', 'great', 'interest', 'bibli...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Im a die hard Dads Army fan and nothing will e...</td>\n      <td>1</td>\n      <td>['im', 'die', 'hard', 'dad', 'army', 'fan', 'n...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19995</th>\n      <td>I was required to watch the movie for my work,...</td>\n      <td>0</td>\n      <td>['required', 'watch', 'movie', 'work', 'pay', ...</td>\n    </tr>\n    <tr>\n      <th>19996</th>\n      <td>\"White Noise\" had potential to be one of the m...</td>\n      <td>0</td>\n      <td>['white', 'noise', 'potential', 'one', 'talked...</td>\n    </tr>\n    <tr>\n      <th>19997</th>\n      <td>The Five Deadly Venoms is a great kung-fu acti...</td>\n      <td>1</td>\n      <td>['five', 'deadly', 'venom', 'great', 'action',...</td>\n    </tr>\n    <tr>\n      <th>19998</th>\n      <td>Ali G Indahouse has got to be one of the funni...</td>\n      <td>1</td>\n      <td>['ali', 'g', 'indahouse', 'got', 'one', 'funni...</td>\n    </tr>\n    <tr>\n      <th>19999</th>\n      <td>I found myself at sixes and sevens while watch...</td>\n      <td>1</td>\n      <td>['found', 'six', 'seven', 'watching', 'one', '...</td>\n    </tr>\n  </tbody>\n</table>\n<p>20000 rows × 3 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679891764721
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}